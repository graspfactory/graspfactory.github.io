<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="description"
    content="Large object centric grasping dataset for industrial grasping applications.">
  <meta name="keywords" content="Robot grasp, Object-Centric Dataset, ">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>GraspFactory: A Large Object-Centric Grasping Dataset</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <!-- <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script> -->
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>

<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">GraspFactory: A Large Object-Centric Grasping Dataset</h1>
            <div class="is-size-3 publication-conference">
              <em>Accepted to 2025 CoRL Data Workshop</strong></em>

            <!-- Authors -->
            <div class="is-size-4 publication-authors">
              <span class="author-block">
                <a href="https://srinidhibharadwaj.github.io">Srinidhi Kalgundi Srinivas</a><sup>†</sup>,
              </span>
              <span class="author-block">
                Yash Shukla<sup>‡§</sup>,
              </span>
              <span class="author-block">
                Adam Arnold<sup>†</sup>,
              </span>
              <span class="author-block">
                Sachin Chitta<sup>†</sup>
              </span>
            </div>

            <!-- Affiliations -->
            <div class="is-size-6 publication-authors">
              <span class="author-block"><sup>†</sup>Autodesk Research</span>
              <span class="author-block"><sup>‡</sup>Berkshire Grey</span>
            </div>

            <!-- Intern note -->
            <div class="is-size-7 publication-authors">
              <span class="author-block"><sup>§</sup>Work done as an intern at Autodesk Research</span>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">

                <!-- Paper Link. -->
                <span class="link-block">
                  <a href="https://arxiv.org/pdf/2011.12948" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Paper</span>
                  </a>
                </span>
          
                <!-- Video Link. -->
                <span class="link-block">
                  <a href="https://www.youtube.com/watch?v=Gs67-cjiTpc"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-youtube"></i>
                    </span>
                    <span>Video</span>
                  </a>
                </span>

                <!-- Code Link. -->
                <span class="link-block">
                  <a href="https://github.com/google/nerfies" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>
                <!-- Dataset Link. -->
                <span class="link-block">
                  <a href="https://github.com/google/nerfies/releases/tag/0.1"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="far fa-images"></i>
                    </span>
                    <span>Data</span>
                  </a>
              </div>

            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="hero teaser">
    <div class="container is-max-desktop">
      <div class="hero-body">
        <video id="teaser" autoplay muted loop playsinline height="100%">
          <source src="./static/videos/teaser.mp4" type="video/mp4">
        </video>
        <h2 class="subtitle has-text-centered">
          <span class="dnerf">Nerfies</span> turns selfie videos from your phone into
          free-viewpoint
          portraits.
        </h2>
      </div>
    </div>
  </section>


  <section class="hero is-light is-small">

  </section>


  <section class="section">
    <div class="container is-max-desktop">
      <!-- Abstract. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
              Robotic grasping is a crucial task in industrial automation, where robots are increasingly expected to
              handle a wide range of objects. However, a significant challenge arises when robot grasping models trained
              on limited datasets encounter novel objects. In real-world environments such as warehouses or
              manufacturing plants, the diversity of objects can be vast, and grasping models need to generalize to this
              diversity. Training large, generalizable robot-grasping models requires geometrically diverse datasets. In
              this paper, we introduce GraspFactory, a dataset containing over 109 million 6-DoF grasps collectively for
              the Franka Panda (with 14,690 objects) and Robotiq 2F85 grippers (with 33,710 objects). GraspFactory is
              designed for training data-intensive models, and we demonstrate the generalization capabilities of one
              such model trained on a subset of GraspFactory in both simulated and real-world settings. We aim to make
              the dataset publicly available after review.
            </p>
          </div>
        </div>
      </div>
      <!--/ Abstract. -->

      <!-- Paper video. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Video</h2>
          <div class="publication-video">
            <iframe src="https://www.youtube.com/watch?v=Gs67-cjiTpc" frameborder="0"
              allow="autoplay; encrypted-media" allowfullscreen></iframe>
          </div>
        </div>
      </div>
      <!--/ Paper video. -->
    </div>



    <section class="section" id="BibTeX">
      <div class="container is-max-desktop content">
        <h2 class="title">BibTeX</h2>
        <pre><code>@article{park2021nerfies,
  author    = {Park, Keunhong and Sinha, Utkarsh and Barron, Jonathan T. and Bouaziz, Sofien and Goldman, Dan B and Seitz, Steven M. and Martin-Brualla, Ricardo},
  title     = {Nerfies: Deformable Neural Radiance Fields},
  journal   = {ICCV},
  year      = {2021},
}</code></pre>
      </div>
    </section>


    <footer class="footer">
      <div class="container">
        <!-- <div class="content has-text-centered">
      <a class="icon-link"
         href="./static/videos/nerfies_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div> -->
        <div class="content has-text-centered">
          <div class="content">
            <p>
              Website template borrowed from <a href="https://github.com/nerfies/nerfies.github.io">NeRFies.</a>
            </p>
          </div>
        </div>
      </div>
    </footer>

</body>

</html>